{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ef2fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting import-ipynb\n",
      "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: nbformat in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from import-ipynb) (5.7.0)\n",
      "Requirement already satisfied: IPython in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from import-ipynb) (8.12.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (5.7.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.2.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.4.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (2.11.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from IPython->import-ipynb) (3.0.36)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from nbformat->import-ipynb) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from nbformat->import-ipynb) (5.2.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from nbformat->import-ipynb) (2.16.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.1.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->import-ipynb) (0.2.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat->import-ipynb) (2.5.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat->import-ipynb) (305.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from stack-data->IPython->import-ipynb) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from stack-data->IPython->import-ipynb) (2.0.5)\n",
      "Requirement already satisfied: executing in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from stack-data->IPython->import-ipynb) (0.8.3)\n",
      "Requirement already satisfied: six in c:\\users\\sreek\\anaconda3\\lib\\site-packages (from asttokens->stack-data->IPython->import-ipynb) (1.16.0)\n",
      "Installing collected packages: import-ipynb\n",
      "Successfully installed import-ipynb-0.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install import-ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33260a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb2b666",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#%load model.ipynb\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "#%load model.ipynb\n",
    "from model import model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c2b84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "..oops you need a JSON file called 'key.json' inside the path './api_key/'\n",
      "(see the README.md to find out how to structure it)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q-Learning for the greater good.. choose how to interact with the API:\n",
      "\n",
      "\n",
      "option 't' is train (default)\n",
      "option 'c' is train-cycle\n",
      "option 'e' is exploit\n",
      "\n",
      "ENTER OPTION: t\n",
      "\n",
      "which World [0-10] would you like to train on? (default is World 0)\n",
      "WORLD: 0\n",
      "\n",
      "how many epochs would you like to train the agent on World 0 for? (default is 1 epoch)\n",
      "EPOCHS: 1\n",
      "\n",
      "training from scratch for 1 on world 0! \n",
      "(visualizations will be saved to './runs/world_0/')\n",
      "(Q-tables will be saved to './runs/Q-table_world_0'\n",
      "\n",
      "verbosity? (default is yes)\n",
      "([y]/n)? y\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 187\u001b[0m\n\u001b[0;32m    182\u001b[0m \t\texit()\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 187\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 40\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \tv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     37\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m\n\u001b[1;32m---> 40\u001b[0m q_table \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39minit_q_table()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./runs/world_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mworld\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m     43\u001b[0m \tos\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./runs/world_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mworld\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#import ipynb.fs.defs.model\n",
    "#import model\n",
    "#from api import API\n",
    "import numpy as np\n",
    "\n",
    "#import util\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\tif not (os.path.exists(f\"./api_key/key.json\")):\n",
    "\t\tprint(\"\\n\\n..oops you need a JSON file called 'key.json' inside the path './api_key/'\\n(see the README.md to find out how to structure it)\\n\\n\")\n",
    "\t\texit()\n",
    "\n",
    "\tprint(\"\\n\\nQ-Learning for the greater good.. choose how to interact with the API:\\n\")\n",
    "\n",
    "\tmode = str(input(\"\\noption 't' is train (default)\\noption 'c' is train-cycle\\noption 'e' is exploit\\n\\nENTER OPTION: \") or \"t\")\n",
    "\n",
    "\tif mode == \"t\":\n",
    "\n",
    "\t\tworld = int(input(\"\\nwhich World [0-10] would you like to train on? (default is World 0)\\nWORLD: \") or \"0\")\n",
    "\n",
    "\t\tepochs = int(input(f\"\\nhow many epochs would you like to train the agent on World {world} for? (default is 1 epoch)\\nEPOCHS: \") or \"1\")\n",
    "\n",
    "\n",
    "\t\tprint(f\"\\ntraining from scratch for {epochs} on world {world}! \\n(visualizations will be saved to './runs/world_{world}/')\\n(Q-tables will be saved to './runs/Q-table_world_{world}'\")\n",
    "\n",
    "\t\tverbose = str(input(f\"\\nverbosity? (default is yes)\\n([y]/n)? \") or \"y\")\n",
    "\t\tif verbose == \"y\":\n",
    "\t\t\tv = True\n",
    "\t\telse:\n",
    "\t\t\tv = False\n",
    "\n",
    "\t\tepsilon = 0.9\n",
    "\n",
    "\n",
    "\t\tq_table = model.init_q_table()\n",
    "\n",
    "\t\tif not (os.path.exists(f\"./runs/world_{world}/\")):\n",
    "\t\t\tos.makedirs(f\"./runs/world_{world}/\")\n",
    "\n",
    "\t\trun_num = len([i for i in os.listdir(f\"runs/world_{world}\")])\n",
    "\n",
    "\n",
    "\n",
    "\t\tfile_path = f\"./runs/Q-table_world_{world}\"\n",
    "\n",
    "\n",
    "\t\tgood_term_states = []\n",
    "\t\tbad_term_states = []\n",
    "\t\tobstacles = []\n",
    "\n",
    "\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tprint(\"EPOCH #\"+str(epoch)+\":\\n\\n\")\n",
    "\t\t\tq_table, good_term_states, bad_term_states, obstacles = model.learn(\n",
    "\t\t\t\tq_table, worldId=world, mode='train', learning_rate=0.0001, gamma=0.9, epsilon=epsilon, good_term_states=good_term_states, bad_term_states=bad_term_states,\n",
    "\t\t\t\tepoch=epoch, obstacles=obstacles, run_num=run_num, verbose=v)\n",
    "\n",
    "\t\t\tepsilon = utils.epsilon_decay(epsilon, epoch, epochs)\n",
    "\n",
    "\t\t\tnp.save(file_path, q_table)\n",
    "\t\tnp.save(f\"./runs/obstacles_world_{world}\", obstacles)\n",
    "\t\tnp.save(f\"./runs/good_term_states_world_{world}\", good_term_states)\n",
    "\t\tnp.save(f\"./runs/bad_term_states_world_{world}\", bad_term_states)\n",
    "\n",
    "\telif mode == \"e\":\n",
    "\t\t\n",
    "\t\tworld = int(input(\"\\nwhich World [0-10] would you like the agent to exploit? (default is World 0)\\nWORLD: \") or \"0\")\n",
    "\t\tepochs = int(input(f\"\\nhow many times would you like the agent to run on World {world} for? (default is 1 time)\\nEPOCHS: \") or \"1\")\n",
    "\n",
    "\t\tverbose = str(input(f\"\\nverbosity? (default is yes)\\n([y]/n)? \") or \"y\")\n",
    "\t\tif verbose == \"y\":\n",
    "\t\t\tv = True\n",
    "\t\telse:\n",
    "\t\t\tv = False\n",
    "\n",
    "\t\tprint(f\"\\nExploiting world {world} for {epochs} iterations! \\n(visualizations will be saved to './runs/world_{world}/')\")\n",
    "\n",
    "\t\tfile_path = f\"./runs/Q-table_world_{world}\"\n",
    "\t\tq_table = np.load(file_path+\".npy\")\n",
    "\n",
    "\t\tobstacles = np.load(f\"./runs/obstacles_world_{world}\"+\".npy\")\n",
    "\t\tgood_term_states = np.load(f\"./runs/good_term_states_world_{world}\"+\".npy\")\n",
    "\t\tbad_term_states = np.load(f\"./runs/bad_term_states_world_{world}\"+\".npy\")\n",
    "\n",
    "\t\tobstacles = obstacles.tolist()\n",
    "\t\tgood_term_states = good_term_states.tolist()\n",
    "\t\tbad_term_states = bad_term_states.tolist()\n",
    "\n",
    "\t\tepsilon = 0.9\n",
    "\t\trun_num = len([i for i in os.listdir(f\"runs/world_{world}\")])\n",
    "\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tprint(\"EPOCH #\"+str(epoch)+\":\\n\\n\")\n",
    "\t\t\tq_table, good_term_states, bad_term_states, obstacles = model.learn(\n",
    "\t\t\t\tq_table, worldId=world, mode='expl', learning_rate=0.0001, gamma=0.9, epsilon=epsilon, good_term_states=good_term_states, bad_term_states=bad_term_states,\n",
    "\t\t\t\tepoch=epoch, obstacles=obstacles, run_num=run_num, verbose=v)\n",
    "\t\n",
    "\n",
    "\tif mode == \"c\":\n",
    "\t\tconfirm = str(input(f\"\\nyou've chosen to train the agent on all Worlds [1-10], this could take a while.. (are you sure?)\\nProceed ([y]/n)? \") or \"y\")\n",
    "\n",
    "\t\tcont = str(input(f\"\\nWould you like to continue training from previous runs? (are you sure?)\\nProceed ([y]/n)? \") or \"y\")\n",
    "\n",
    "\t\tif cont.lower() == \"y\":\n",
    "\t\t\tepochs_computed = int(input(f\"\\nHow many epochs were used in previous training runs?\\nEPOCHS: \"))\n",
    "\t\t\tepochs = int(input(f\"\\nhow many more epochs would you the agent to train on each World? (default is 10 epochs)\\nEPOCHS: \") or \"10\")\n",
    "\t\t\tinit_eps = epsilon = utils.epsilon_decay(0.9, 6, epochs_computed+epochs)\n",
    "\t\telse:\n",
    "\t\t\tepochs = int(input(f\"\\nhow many epochs would you the agent to train on each World? (default is 10 epochs)\\nEPOCHS: \") or \"10\")\n",
    "\t\t\tepochs_computed = 0\n",
    "\t\t\tinit_eps = epsilon = 0.9\n",
    "\n",
    "\t\tverbose = str(input(f\"\\nverbosity? (default is yes)\\n([y]/n)? \") or \"y\")\n",
    "\t\tif verbose == \"y\":\n",
    "\t\t\tv = True\n",
    "\t\telse:\n",
    "\t\t\tv = False\n",
    "\n",
    "\t\tif confirm == \"y\":\n",
    "\t\t\tfor i in range(10):\n",
    "\t\t\t\tworld = i+1\n",
    "\n",
    "\t\t\t\tprint(f\"\\ntraining from scratch for {epochs} on world {world}! \\n(visualizations will be saved to './runs/world_{world}/')\\n(Q-tables will be saved to './runs/Q-table_world_{world}'\")\n",
    "\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\tif not (os.path.exists(f\"./runs/world_{world}/\")):\n",
    "\t\t\t\t\tos.makedirs(f\"./runs/world_{world}/\")\n",
    "\n",
    "\t\t\t\trun_num = len([i for i in os.listdir(f\"runs/world_{world}\")])\n",
    "\n",
    "\n",
    "\t\t\t\tfile_path = f\"./runs/Q-table_world_{world}\"\n",
    "\n",
    "\t\t\t\tif cont.lower() == 'y':\n",
    "\t\t\t\t\tgood_term_states = np.load(open(f\"./runs/good_term_states_world_{world}.npy\", \"rb\"))\n",
    "\t\t\t\t\tbad_term_states = np.load(open(f\"./runs/bad_term_states_world_{world}.npy\", \"rb\"))\n",
    "\t\t\t\t\tobstacles = np.load(open(f\"./runs/obstacles_world_{world}.npy\", \"rb\"))\n",
    "\n",
    "\t\t\t\t\tq_table = np.load(open(f\"./runs/Q-table_world_{world}.npy\", \"rb\"))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tgood_term_states = []\n",
    "\t\t\t\t\tbad_term_states = []\n",
    "\t\t\t\t\tobstacles = []\n",
    "\t\t\t\t\tq_table = model.init_q_table()\n",
    "\t\t\t\t\n",
    "\t\t\t\tt = trange(epochs, desc='Training on all worlds', leave=True)\n",
    "\n",
    "\t\t\t\tfor epoch in t:\n",
    "\t\t\t\t\tt.set_description('Current World={}'.format(i+1))\n",
    "\n",
    "\t\t\t\t\tprint(\"EPOCH #\"+str(epoch)+\":\\n\\n\")\n",
    "\t\t\t\t\tq_table, good_term_states, bad_term_states, obstacles = model.learn(\n",
    "\t\t\t\t\t\tq_table, worldId=world, mode='train', learning_rate=0.0001, gamma=0.9, epsilon=epsilon, good_term_states=good_term_states, bad_term_states=bad_term_states,\n",
    "\t\t\t\t\t\tepoch=epoch, obstacles=obstacles, run_num=run_num, verbose=v)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tepsilon = utils.epsilon_decay(init_eps, epoch+epochs_computed, epochs+epochs_computed)\n",
    "\n",
    "\t\t\t\t\tnp.save(file_path, q_table)\n",
    "\n",
    "\t\t\t\tnp.save(f\"./runs/obstacles_world_{world}\", obstacles)\n",
    "\t\t\t\tnp.save(f\"./runs/good_term_states_world_{world}\", good_term_states)\n",
    "\t\t\t\tnp.save(f\"./runs/bad_term_states_world_{world}\", bad_term_states)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\t#confirmation not given\n",
    "\t\t\texit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\telse:\n",
    "\t\tprint(\"that option doesn't exist yet :'(\")\n",
    "\t\texit()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18575f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
